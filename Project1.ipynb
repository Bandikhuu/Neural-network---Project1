{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading  train-images-idx3-ubyte.gz\n",
      "Downloading  train-labels-idx1-ubyte.gz\n",
      "Downloading  t10k-images-idx3-ubyte.gz\n",
      "Downloading  t10k-labels-idx1-ubyte.gz\n",
      "All files are available\n"
     ]
    }
   ],
   "source": [
    "#IMPORTS\n",
    "import os,urllib.request\n",
    "\n",
    "# PROVIDE YOUR DOWNLOAD DIRECTORY HERE\n",
    "datapath = '../../Data/MNISTData/'\n",
    "\n",
    "# CREATING DOWNLOAD DIRECTORY\n",
    "if not os.path.exists(datapath):\n",
    "    os.makedirs(datapath)\n",
    "\n",
    "# URLS TO DOWNLOAD FROM\n",
    "urls = ['http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
    "       'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
    "       'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
    "       'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz']\n",
    "\n",
    "for url in urls:\n",
    "    filename = url.split('/')[-1]   # GET FILENAME\n",
    "    \n",
    "    if os.path.exists(datapath+filename):\n",
    "        print(filename, ' already exists')  # CHECK IF FILE EXISTS\n",
    "    else:\n",
    "        print('Downloading ',filename)\n",
    "        urllib.request.urlretrieve (url, datapath+filename) # DOWNLOAD FILE\n",
    "     \n",
    "print('All files are available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting  t10k-images-idx3-ubyte.gz\n",
      "Extracting  train-images-idx3-ubyte.gz\n",
      "Extracting  train-labels-idx1-ubyte.gz\n",
      "Extracting  t10k-labels-idx1-ubyte.gz\n",
      "Extraction Complete\n",
      "Removing  t10k-images-idx3-ubyte.gz\n",
      "Removing  train-images-idx3-ubyte.gz\n",
      "Removing  train-labels-idx1-ubyte.gz\n",
      "Removing  t10k-labels-idx1-ubyte.gz\n",
      "All archives removed\n"
     ]
    }
   ],
   "source": [
    "import os,gzip,shutil\n",
    "\n",
    "# PROVIDE YOUR DOWNLOAD DIRECTORY HERE\n",
    "datapath = '../../Data/MNISTData/'  \n",
    "\n",
    "# LISTING ALL ARCHIVES IN THE DIRECTORY\n",
    "files = os.listdir(datapath)\n",
    "for file in files:\n",
    "    if file.endswith('gz'):\n",
    "        print('Extracting ',file)\n",
    "        with gzip.open(datapath+file, 'rb') as f_in:\n",
    "            with open(datapath+file.split('.')[0], 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "print('Extraction Complete')\n",
    "\n",
    "# OPTIONAL REMOVE THE ARCHIVES\n",
    "for file in files:\n",
    "    print('Removing ',file)\n",
    "    os.remove(datapath+file)\n",
    "print ('All archives removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading  t10k-images-idx3-ubyte\n",
      "Reading  t10k-labels-idx1-ubyte\n",
      "Reading  train-images-idx3-ubyte\n",
      "Reading  train-labels-idx1-ubyte\n"
     ]
    }
   ],
   "source": [
    "import os,codecs,numpy\n",
    "\n",
    "# PROVIDE YOUR DIRECTORY WITH THE EXTRACTED FILES HERE\n",
    "datapath = '../../Data/MNISTData/'\n",
    "\n",
    "files = os.listdir(datapath)\n",
    "\n",
    "def get_int(b):   # CONVERTS 4 BYTES TO A INT\n",
    "    return int(codecs.encode(b, 'hex'), 16)\n",
    "\n",
    "data_dict = {}\n",
    "for file in files:\n",
    "    if file.endswith('ubyte'):  # FOR ALL 'ubyte' FILES\n",
    "        print('Reading ',file)\n",
    "        with open (datapath+file,'rb') as f:\n",
    "            data = f.read()\n",
    "            type = get_int(data[:4])   # 0-3: THE MAGIC NUMBER TO WHETHER IMAGE OR LABEL\n",
    "            length = get_int(data[4:8])  # 4-7: LENGTH OF THE ARRAY  (DIMENSION 0)\n",
    "            if (type == 2051):\n",
    "                category = 'images'\n",
    "                num_rows = get_int(data[8:12])  # NUMBER OF ROWS  (DIMENSION 1)\n",
    "                num_cols = get_int(data[12:16])  # NUMBER OF COLUMNS  (DIMENSION 2)\n",
    "                parsed = numpy.frombuffer(data,dtype = numpy.uint8, offset = 16)  # READ THE PIXEL VALUES AS INTEGERS\n",
    "                parsed = parsed.reshape(length,num_rows,num_cols)  # RESHAPE THE ARRAY AS [NO_OF_SAMPLES x HEIGHT x WIDTH]           \n",
    "            elif(type == 2049):\n",
    "                category = 'labels'\n",
    "                parsed = numpy.frombuffer(data, dtype=numpy.uint8, offset=8) # READ THE LABEL VALUES AS INTEGERS\n",
    "                parsed = parsed.reshape(length)  # RESHAPE THE ARRAY AS [NO_OF_SAMPLES]                           \n",
    "            if (length==10000):\n",
    "                set = 'test'\n",
    "            elif (length==60000):\n",
    "                set = 'train'\n",
    "            data_dict[set+'_'+category] = parsed  # SAVE THE NUMPY ARRAY TO A CORRESPONDING KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "train_images = data_dict['train_images']\n",
    "print(train_images.shape)\n",
    "train_labels = data_dict['train_labels']\n",
    "print(train_labels.shape)\n",
    "test_images = data_dict['test_images']\n",
    "print(test_images.shape)\n",
    "test_labels = data_dict['test_labels']\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ...\n",
      "train image shape:\n",
      "(60000, 28, 28)\n",
      "test image shape:\n",
      "(10000, 28, 28)\n",
      "Сургах өгөгдлөө 2 хэмжээст болгож байна.\n",
      "(60000, 784)\n",
      "Турших өгөгдлөө 2 хэмжээст болгож байна.\n",
      "(10000, 784)\n",
      "Loss: 4.604725245638579\n",
      "Loss: 4.6512882493836845\n",
      "Loss: 4.6523937052444975\n",
      "Loss: 4.651995789185555\n",
      "Loss: 4.651839628563409\n",
      "Loss: 4.651179493929227\n",
      "Loss: 4.6513993088887995\n",
      "Loss: 4.651408934243461\n",
      "Loss: 4.651249784620968\n",
      "Loss: 4.6519499539421005\n",
      "4.6519499539421005\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import array\n",
    "\n",
    "# Энд train_images гэсэн энгийн array - г numpy-ын array болгож байна. \n",
    "\n",
    "np.array(train_images)\n",
    "np.array(train_labels)\n",
    "np.array(test_images)\n",
    "np.array(test_labels)\n",
    "\n",
    "class Neural_network:\n",
    "    def __init__(train_image_size,picture_size,hidden_layer_size,output_layer_size,batch_size):\n",
    "        # Divisor нь 0-1 н хооронд болгохын тулд үржиж байгаа тоо.\n",
    "        divisor = 1/255\n",
    "        # Харин энд зураг тус бүрийг 0-1 хооронд байхаар pixel бүрээр үржиж байна гэсэн үг.\n",
    "        c_train_image = train_images*(divisor)\n",
    "        c_test_image = test_images*(divisor)\n",
    "        \n",
    "        print(\"train image shape:\")\n",
    "        print(c_train_image.shape)\n",
    "        print(\"test image shape:\")\n",
    "        print(c_test_image.shape)\n",
    "        \n",
    "        # Энд (60000,28,28) хэмжээтэй зураг аа (60000,784) хэмжээтэй болгож байна.\n",
    "        cv_train_image = np.reshape(c_train_image,(60000,784))\n",
    "        print(\"Сургах өгөгдлөө 2 хэмжээст болгож байна.\")\n",
    "        print(cv_train_image.shape)\n",
    "        cv_test_image = np.reshape(c_test_image,(10000,784))\n",
    "        print(\"Турших өгөгдлөө 2 хэмжээст болгож байна.\")\n",
    "        print(cv_test_image.shape)\n",
    "    \n",
    "    def generate_random(self,picture_size,hidden_layer_size,output_layer_size):\n",
    "        w1 = np.random.randn(picture_size,hidden_layer_size)*0.01\n",
    "        b1 = np.zeros((1,hidden_layer_size))\n",
    "        w2 = np.random.randn(hidden_layer_size,output_layer_size)*0.01\n",
    "        b2 = np.zeros((1,output_layer_size))\n",
    "        return w1,w2,b1,b2\n",
    "    \n",
    "    def softmax(self,x):\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum(axis=0) # only difference\n",
    "    \n",
    "    def relu(self,x):\n",
    "        return np.maximum(0,x)\n",
    "        \n",
    "    def compute_loss(self,w1,b1,w2,b2):\n",
    "        batch_size = 100\n",
    "        loss = 0\n",
    "        for index in range(0,1000,batch_size):\n",
    "            batch=cv_train_image[index:min(index+batch_size,cv_train_image.shape[0]),:]\n",
    "            layer1 = np.add(batch@w1,b1)\n",
    "            layer1 = relu(layer1)\n",
    "            layer2 = np.add(layer1@w2,b2)\n",
    "            layer2 = softmax(layer2)\n",
    "            for i in range(batch_size):\n",
    "                correct_logprobs = -np.log(layer2[i,train_labels[i]])\n",
    "                loss = loss + correct_logprobs\n",
    "#                 print(i)\n",
    "#                 print(\"Correct:\",correct_logprobs)\n",
    "            loss = loss / batch_size\n",
    "            print(\"Loss:\",loss)\n",
    "        return loss        \n",
    "# Сургах зурагны тоо\n",
    "train_image_size = 60000\n",
    "picture_size = 784\n",
    "hidden_layer_size = 32\n",
    "output_layer_size = 10\n",
    "batch_size = 100\n",
    "print(\"Starting ...\")\n",
    "Object1 = Neural_network(train_image_size,picture_size,hidden_layer_size,output_layer_size)\n",
    "w1,w2,b1,b2 = Object1.generate_random(picture_size,hidden_layer_size,output_layer_size)\n",
    "loss = Object1.compute_loss(w1,b1,w2,b2)\n",
    "print(loss)\n",
    "\n",
    "# def softmax(inputs):\n",
    "#     return np.exp(inputs) / float(sum(np.exp(inputs)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
